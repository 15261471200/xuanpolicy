Welcome to XuanPolicy!
========================================

**XuanPolicy** is an open-source ensemble of Deep Reinforcement Learning (DRL) algorithm implementations.

We call it as **Xuan-Ce (玄策)** in Chinese.
"**Xuan (玄)**" means incredible and magic box, "**Ce (策)**" means policy.

DRL algorithms are sensitive to hyper-parameters tuning, varying in performance with different tricks,
and suffering from unstable training processes, therefore, sometimes DRL algorithms seems elusive and "Xuan".
This project gives a thorough, high-quality and easy-to-understand implementation of DRL algorithms,
and hope this implementation can give a hint on the magics of reinforcement learning.

We expect it to be compatible with multiple deep learning toolboxes(
PyTorch_,
TensorFlow_, and
MindSpore_,
and hope it can really become a zoo full of DRL algorithms.

.. _PyTorch: https://pytorch.org/
.. _TensorFlow: https://www.tensorflow.org/
.. _MindSpore: https://www.mindspore.cn/en


Currently Supported Agents
====================================

Single-agent DRL
------------------------
.. toctree::
   :maxdepth: 2
   :caption: Single-agent DRL

   agents/drl/dqn
   agents/drl/cdqn
   agents/drl/c51
   agents/drl/cldqn
   agents/drl/ddqn
   agents/drl/dueldqn
   agents/drl/ldqn
   agents/drl/noisydqn
   agents/drl/perdqn
   agents/drl/qrdqn
   agents/drl/vpg
   agents/drl/ppg
   agents/drl/ppo
   agents/drl/pdqn
   agents/drl/spdqn
   agents/drl/mpdqn
   agents/drl/a2c
   agents/drl/sac
   agents/drl/sac-dis
   agents/drl/td3
   agents/drl/ddpg

Multi-agent Reinforcement Learning (MARL)
------------------------

.. toctree::
   :maxdepth: 2
   :caption: MARL

   agents/marl/iql
   agents/marl/vdn
   agents/marl/qtran
   agents/marl/qmix
   agents/marl/wqmix
   agents/marl/dcg
   agents/marl/mfq
   agents/marl/mfac
   agents/marl/mappo
   agents/marl/coma
   agents/marl/isac
   agents/marl/masac
   agents/marl/iddpg
   agents/marl/maddpg
   agents/marl/matd3
   agents/marl/vdac

Installation
====================================



Tutorial
====================================



